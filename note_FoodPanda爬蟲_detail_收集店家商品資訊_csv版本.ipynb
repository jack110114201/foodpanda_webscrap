{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82ea5bb9",
   "metadata": {},
   "source": [
    "## 透過店家url查詢相關商品資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91991192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '', 'createtime': '', 'data_adr': '', 'data_time': [{'name': 'A', 'dayOfWeek': 'B', 'opens_time': 'C', 'closes_time': 'D'}], 'data_feature_detail': [], 'data_product_detail': []}\n",
      "{'name': '', 'createtime': '', 'data_adr': '', 'data_time': [{'name': 'A', 'dayOfWeek': 'B', 'opens_time': 'C', 'closes_time': 'D'}, {'name': 'CCCC', 'dayOfWeek': 'DDDD', 'opens_time': 'C', 'closes_time': 'D'}], 'data_feature_detail': [], 'data_product_detail': []}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "scrap_data = {\n",
    "            'name': '',\n",
    "            'createtime' : '',\n",
    "            'data_adr': '',\n",
    "            'data_time' : [],\n",
    "            'data_feature_detail' : [],\n",
    "            'data_product_detail' : []\n",
    "            }\n",
    "data_time = {\n",
    "            'name' : 'A',\n",
    "            'dayOfWeek' : 'B',\n",
    "            'opens_time' : 'C',\n",
    "            'closes_time' : 'D'\n",
    "            }\n",
    "scrap_data['data_time'].append(data_time)\n",
    "print(scrap_data)\n",
    "data_time = {\n",
    "            'name' : 'CCCC',\n",
    "            'dayOfWeek' : 'DDDD',\n",
    "            'opens_time' : 'C',\n",
    "            'closes_time' : 'D'\n",
    "            }\n",
    "scrap_data['data_time'].append(data_time)\n",
    "print(scrap_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd0036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import error as urlliberror\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import http.client\n",
    "\n",
    "\n",
    "path = os.path.dirname(os.path.abspath('__file__'))  # 檔案所在的目錄路徑\n",
    "prefix = \"shop_url\"  # 檔案名稱前綴\n",
    "\n",
    "# 列出目錄下所有以指定前綴開頭的檔案\n",
    "files = [f for f in os.listdir(path) if f.startswith(prefix)]\n",
    "\n",
    "# 將檔案按照最後修改時間排序，並取最後一個即為最新創建的檔案\n",
    "latest_url_file = sorted(files, key=lambda x: os.path.getmtime(os.path.join(path, x)), reverse=True)[0]\n",
    "\n",
    "print(\"最新創建的檔案是:\", latest_url_file)\n",
    "\n",
    "\n",
    "data_adr = {\n",
    "'name' : '',\n",
    "'country' : '',\n",
    "'postalCode' : '',\n",
    "'address' : '',\n",
    "'latitude' : '',\n",
    "'longitude' : '',\n",
    "'telephone' : ''    \n",
    "}\n",
    "\n",
    "data_time = {\n",
    "'name' : '',\n",
    "'dayOfWeek' : '',\n",
    "'opens_time' : '',\n",
    "'closes_time' : ''\n",
    "}\n",
    "\n",
    "data_feature_detail = {\n",
    "'name' : '',\n",
    "'feature' : ''\n",
    "}\n",
    "\n",
    "data_product_detail = {\n",
    "'name' : '',\n",
    "'product' : '',\n",
    "'price' : '',\n",
    "}\n",
    "\n",
    "\n",
    "delay_choices = [5, 6, 7]  #延遲的秒數\n",
    "detail_delay = random.choice(delay_choices)  #隨機選取秒數   \n",
    "detail_scroll = random.uniform(1500, 2500)  #隨機選取拉動幅度\n",
    "\n",
    "createtime = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "shop_adr_path = f'./shop_adr_{createtime}.csv'\n",
    "shop_time_path = f'./shop_time_{createtime}.csv'\n",
    "shop_feature_detail_path = f'./shop_feature_detail_{createtime}.csv'\n",
    "shop_product_detail_path = f'./shop_product_detail_{createtime}.csv'\n",
    "  \n",
    "\n",
    "\n",
    "cnt = 0\n",
    "with open(latest_url_file, \"r\") as ref_url,\\\n",
    "     open(shop_adr_path,'w',newline='', encoding=\"utf8\") as shop_adr_file,\\\n",
    "     open(shop_time_path,'w',newline='', encoding=\"utf8\") as shop_time_file,\\\n",
    "     open(shop_feature_detail_path,'w',newline='', encoding=\"utf8\") as shop_feature_detail_file,\\\n",
    "     open(shop_product_detail_path,'w',newline='', encoding=\"utf8\") as shop_product_detail_file:\n",
    "    \n",
    "    shop_adr_writer = csv.DictWriter(shop_adr_file, fieldnames=[*data_adr.keys()], delimiter=\",\")\n",
    "    shop_time_writer = csv.DictWriter(shop_time_file, fieldnames=[*data_time.keys()], delimiter=\",\")\n",
    "    shop_feature_detail_writer = csv.DictWriter(shop_feature_detail_file, fieldnames=[*data_feature_detail.keys()], delimiter=\",\")\n",
    "    shop_product_detail_writer = csv.DictWriter(shop_product_detail_file, fieldnames=[*data_product_detail.keys()], delimiter=\",\")\n",
    "    \n",
    "    shop_adr_writer.writeheader()\n",
    "    shop_time_writer.writeheader()\n",
    "    shop_feature_detail_writer.writeheader()\n",
    "    shop_product_detail_writer.writeheader()\n",
    "\n",
    "    reader = csv.reader(ref_url)\n",
    "    header = next(reader)  # 讀取標題行\n",
    "    for row in reader:\n",
    "        print(row[0],':',row[1])\n",
    "        \n",
    "\n",
    "        options = uc.ChromeOptions()\n",
    "        #options.headless=True\n",
    "        # https://github.com/ultrafunkamsterdam/undetected-chromedriver/issues/743\n",
    "        # https://ithelp.ithome.com.tw/articles/10255430\n",
    "        #options.add_argument('--headless=new')\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument('--disable-dev-shm-usage')\n",
    "        browser = uc.Chrome(options=options)\n",
    "\n",
    "        browser.get(row[1])\n",
    "        time.sleep(detail_delay)\n",
    "        ActionChains(browser).move_by_offset(20, 20).click().perform() # 鼠標左鍵點擊， 200爲x座標， 100爲y座標\n",
    "        time.sleep(detail_delay)\n",
    "        for i in range(3):\n",
    "            browser.execute_script('window.scrollBy(0, {x});'.format(x = detail_scroll))\n",
    "            time.sleep(detail_delay)\n",
    "        \n",
    "        html_source = browser.page_source\n",
    "        #print(html_source)\n",
    "        soup = BeautifulSoup(html_source, \"html.parser\")\n",
    "\n",
    "        try:\n",
    "            json_script = soup.find(\"script\",{'data-testid': 'restaurant-seo-schema'})\n",
    "            json_text = json_script.string\n",
    "            shop_data = json.loads(json_text)\n",
    "            shop_data\n",
    "\n",
    "            # data_adr資訊\n",
    "            data_adr['name'] = shop_data['name']\n",
    "            data_adr['country'] = shop_data['address']['addressCountry']\n",
    "            data_adr['postalCode'] = shop_data['address']['postalCode']\n",
    "            data_adr['address'] = shop_data['address']['streetAddress'].split(')')[1]\n",
    "            data_adr['latitude'] = shop_data['areaServed']['geoMidpoint']['latitude']\n",
    "            data_adr['longitude'] = shop_data['areaServed']['geoMidpoint']['longitude']\n",
    "            data_adr['telephone'] = shop_data['telephone']\n",
    "            shop_adr_writer.writerow(data_adr)\n",
    "\n",
    "            # data_time資訊      \n",
    "            for time_detail in shop_data['openingHoursSpecification']:\n",
    "                for k in time_detail['dayOfWeek']:\n",
    "                    data_time['name'] = shop_data['name']\n",
    "                    data_time['dayOfWeek'] = k\n",
    "                    data_time['opens_time'] = time_detail['opens']\n",
    "                    data_time['closes_time'] = time_detail['closes']\n",
    "                    shop_time_writer.writerow(data_time)\n",
    "            \n",
    "            # data_feature_detail資訊 \n",
    "            for feature in shop_data['servesCuisine']:\n",
    "                data_feature_detail['name'] = shop_data['name']\n",
    "                data_feature_detail['feature'] = feature \n",
    "                shop_feature_detail_writer.writerow(data_feature_detail)\n",
    "        \n",
    "            #data_product_detail資訊\n",
    "            products = soup.find_all(\"li\",class_ = 'box-flex dish-card bg-white jc-space-between p-relative sm:pl-zero md:pl-md lg:pl-md pl-sm sm:pr-zero md:pr-md lg:pr-md pr-sm sm:pt-zero md:pt-md lg:pt-md pt-sm sm:pb-sm md:pb-md lg:pb-md pb-sm br-xxs bs-1')\n",
    "  \n",
    "            for i in products:\n",
    "                product_all = i.find(\"button\")['aria-label'].split(',')\n",
    "                product = product_all[0]\n",
    "                price = product_all[1].split('-')[0].strip().replace('$','')\n",
    "                try:\n",
    "                    if int(price) == 0:\n",
    "                        pass\n",
    "                    else:\n",
    "                        data_product_detail['name'] = shop_data['name']\n",
    "                        data_product_detail['product'] = product\n",
    "                        data_product_detail['price'] = price\n",
    "                        shop_product_detail_writer.writerow(data_product_detail)\n",
    "                except:\n",
    "                    pass\n",
    "            # 遇到問題: RemoteDisconnected: Remote end closed connection without response\n",
    "            #browser.close()  \n",
    "            #browser.quit() #https://blog.csdn.net/yangfengjueqi/article/details/84338167\n",
    "            #解決辦法: https://github.com/SeleniumHQ/selenium/issues/8612\n",
    "            conn = http.client.HTTPConnection(browser.service.service_url.split(\"//\")[1])\n",
    "            conn.request(\"GET\", \"/shutdown\")\n",
    "            conn.close()\n",
    "            del browser\n",
    "            cnt += 1\n",
    "            print(cnt)\n",
    "            time.sleep(35)\n",
    "        # https://blog.csdn.net/qq_37163925/article/details/115277342\n",
    "        except urlliberror as e:\n",
    "            if e.errno != errno.ECONNRESET:\n",
    "                exit_code = 1\n",
    "                print(f\"執行{row[0]}過程發生錯誤\")\n",
    "                exit(exit_code)\n",
    "                raise\n",
    "            else:\n",
    "                print(f\"執行{row[0]}過程發生ECONNRESET\")\n",
    "                pass        \n",
    "        except:\n",
    "            exit_code = 1\n",
    "            print(f\"執行{row[0]}過程發生錯誤\")\n",
    "            exit(exit_code)\n",
    "                      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfd7cd29",
   "metadata": {},
   "source": [
    "### 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import error as urlliberror\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import http.client\n",
    "\n",
    "\n",
    "class FoodpandaScraper_product_detail:\n",
    "    def __init__(self):\n",
    "        self.data_adr = {\n",
    "            'name' : '',\n",
    "            'country' : '',\n",
    "            'postalCode' : '',\n",
    "            'address' : '',\n",
    "            'latitude' : '',\n",
    "            'longitude' : '',\n",
    "            'telephone' : ''  \n",
    "            }\n",
    "        self.data_time = {\n",
    "            'name' : '',\n",
    "            'dayOfWeek' : '',\n",
    "            'opens_time' : '',\n",
    "            'closes_time' : ''\n",
    "            }\n",
    "        self.data_feature_detail = {\n",
    "            'name': '',\n",
    "            'feature': ''\n",
    "        }\n",
    "        self.data_product_detail = {\n",
    "            'name' : '',\n",
    "            'product' : '',\n",
    "            'price' : '',\n",
    "            }\n",
    "        self.cnt = 0\n",
    "        self.delay_choices = [5, 6, 7]  #延遲的秒數\n",
    "        self.path = os.path.dirname(os.path.abspath('__file__'))  # 檔案所在的目錄路徑\n",
    "\n",
    "    def find_lastest_url_file(self):\n",
    "        prefix = \"shop_url\"  # 檔案名稱前綴\n",
    "        # 列出目錄下所有以指定前綴開頭的檔案\n",
    "        files = [f for f in os.listdir(self.path) if f.startswith(prefix)]\n",
    "        # 將檔案按照最後修改時間排序，並取最後一個即為最新創建的檔案\n",
    "        latest_url_file_path = sorted(files, key=lambda x: os.path.getmtime(os.path.join(self.path, x)), reverse=True)[0]\n",
    "        print(\"最新創建的檔案是:\", latest_url_file_path)\n",
    "        return latest_url_file_path\n",
    "    \n",
    "    def foodpanda_product_detail(self, createtime):\n",
    "        latest_url_file_path = self.find_lastest_url_file()\n",
    "        shop_adr_path = os.path.join(self.path, f'data/shop_adr_{createtime}.csv')\n",
    "        shop_time_path = os.path.join(self.path, f'data/shop_time_{createtime}.csv')\n",
    "        shop_feature_detail_path = os.path.join(self.path, f'data/shop_feature_detail_{createtime}.csv')\n",
    "        shop_product_detail_path = os.path.join(self.path, f'data/shop_product_detail_{createtime}.csv')\n",
    "\n",
    "        with open(latest_url_file_path, \"r\") as ref_url,\\\n",
    "             open(shop_adr_path,'w',newline='', encoding=\"utf8\") as shop_adr_file,\\\n",
    "             open(shop_time_path,'w',newline='', encoding=\"utf8\") as shop_time_file,\\\n",
    "             open(shop_feature_detail_path,'w',newline='', encoding=\"utf8\") as shop_feature_detail_file,\\\n",
    "             open(shop_product_detail_path,'w',newline='', encoding=\"utf8\") as shop_product_detail_file:\n",
    "            shop_adr_writer = csv.DictWriter(shop_adr_file, fieldnames=[*self.data_adr.keys()], delimiter=\",\")\n",
    "            shop_time_writer = csv.DictWriter(shop_time_file, fieldnames=[*self.data_time.keys()], delimiter=\",\")\n",
    "            shop_feature_detail_writer = csv.DictWriter(shop_feature_detail_file, fieldnames=[*self.data_feature_detail.keys()], delimiter=\",\")\n",
    "            shop_product_detail_writer = csv.DictWriter(shop_product_detail_file, fieldnames=[*self.data_product_detail.keys()], delimiter=\",\")\n",
    "\n",
    "            shop_adr_writer.writeheader()\n",
    "            shop_time_writer.writeheader()\n",
    "            shop_feature_detail_writer.writeheader()\n",
    "            shop_product_detail_writer.writeheader()\n",
    "\n",
    "            # 讀取url file中的data\n",
    "            reader = csv.reader(ref_url)\n",
    "            header = next(reader)  # 讀取標題行,忽略header資料\n",
    "            for row in reader:\n",
    "                print(row[0],':',row[1])\n",
    "                \n",
    "                # 進入爬蟲階段\n",
    "                options = uc.ChromeOptions()\n",
    "                #options.headless=True  \n",
    "                #options.add_argument('--headless=new')\n",
    "                options.add_argument('--no-sandbox')\n",
    "                options.add_argument('--disable-dev-shm-usage')\n",
    "                browser = uc.Chrome(options=options)\n",
    "                browser.get(row[1])\n",
    "                time.sleep(random.choice(self.delay_choices))\n",
    "                ActionChains(browser).move_by_offset(20, 20).click().perform() # 鼠標左鍵點擊， 200爲x座標， 100爲y座標\n",
    "                time.sleep(random.choice(self.delay_choices))\n",
    "                # 滑動頁面\n",
    "                for i in range(3):\n",
    "                    browser.execute_script('window.scrollBy(0, {x});'.format(x = random.uniform(1500, 2500))) #隨機選取拉動幅度\n",
    "                    time.sleep(random.choice(self.delay_choices))\n",
    "                # 取得html資料\n",
    "                html_source = browser.page_source\n",
    "                soup = BeautifulSoup(html_source, \"html.parser\")\n",
    "                try:\n",
    "                    json_script = soup.find(\"script\",{'data-testid': 'restaurant-seo-schema'})\n",
    "                    json_text = json_script.string\n",
    "                    shop_data = json.loads(json_text)\n",
    "\n",
    "                    # data_adr資訊\n",
    "                    self.data_adr['name'] = shop_data['name']\n",
    "                    self.data_adr['country'] = shop_data['address']['addressCountry']\n",
    "                    self.data_adr['postalCode'] = shop_data['address']['postalCode']\n",
    "                    self.data_adr['address'] = shop_data['address']['streetAddress'].split(')')[1]\n",
    "                    self.data_adr['latitude'] = shop_data['areaServed']['geoMidpoint']['latitude']\n",
    "                    self.data_adr['longitude'] = shop_data['areaServed']['geoMidpoint']['longitude']\n",
    "                    self.data_adr['telephone'] = shop_data['telephone']\n",
    "                    shop_adr_writer.writerow(self.data_adr)\n",
    "        \n",
    "                    # data_time資訊      \n",
    "                    for time_detail in shop_data['openingHoursSpecification']:\n",
    "                        for k in time_detail['dayOfWeek']:\n",
    "                            self.data_time['name'] = shop_data['name']\n",
    "                            self.data_time['dayOfWeek'] = k\n",
    "                            self.data_time['opens_time'] = time_detail['opens']\n",
    "                            self.data_time['closes_time'] = time_detail['closes']\n",
    "                            shop_time_writer.writerow(self.data_time)\n",
    "                    \n",
    "                    # data_feature_detail資訊 \n",
    "                    for feature in shop_data['servesCuisine']:\n",
    "                        self.data_feature_detail['name'] = shop_data['name']\n",
    "                        self.data_feature_detail['feature'] = feature \n",
    "                        shop_feature_detail_writer.writerow(self.data_feature_detail)\n",
    "                \n",
    "                    #data_product_detail資訊\n",
    "                    products = soup.find_all(\"li\",class_ = 'box-flex dish-card bg-white jc-space-between p-relative sm:pl-zero md:pl-md lg:pl-md pl-sm sm:pr-zero md:pr-md lg:pr-md pr-sm sm:pt-zero md:pt-md lg:pt-md pt-sm sm:pb-sm md:pb-md lg:pb-md pb-sm br-xxs bs-1')\n",
    "          \n",
    "                    for i in products:\n",
    "                        product_all = i.find(\"button\")['aria-label'].split(',')\n",
    "                        product = product_all[0]\n",
    "                        price = product_all[1].split('-')[0].strip().replace('$','')\n",
    "                        try:\n",
    "                            if int(price) == 0:\n",
    "                                pass\n",
    "                            else:\n",
    "                                self.data_product_detail['name'] = shop_data['name']\n",
    "                                self.data_product_detail['product'] = product\n",
    "                                self.data_product_detail['price'] = price\n",
    "                                shop_product_detail_writer.writerow(self.data_product_detail)\n",
    "                        except:\n",
    "                            pass\n",
    "                    browser.quit() #https://blog.csdn.net/yangfengjueqi/article/details/84338167\n",
    "                    #解決辦法: https://github.com/SeleniumHQ/selenium/issues/8612\n",
    "                    #conn = http.client.HTTPConnection(browser.service.service_url.split(\"//\")[1])\n",
    "                    #conn.request(\"GET\", \"/shutdown\")\n",
    "                    #conn.close()\n",
    "                    #del browser\n",
    "                    self.cnt += 1\n",
    "                    print(self.cnt)\n",
    "                    time.sleep(20)\n",
    "                # https://blog.csdn.net/qq_37163925/article/details/115277342\n",
    "                except urlliberror as e:\n",
    "                    if e.errno != errno.ECONNRESET:\n",
    "                        exit_code = 1\n",
    "                        print(f\"執行{row[0]}過程發生錯誤\")\n",
    "                        exit(exit_code)\n",
    "                        raise\n",
    "                    else:\n",
    "                        print(f\"執行{row[0]}過程發生ECONNRESET\")\n",
    "                        pass        \n",
    "                except:\n",
    "                    exit_code = 1\n",
    "                    print(f\"執行{row[0]}過程發生錯誤\")\n",
    "                    exit(exit_code)  \n",
    "if __name__ == '__main__':\n",
    "    FoodpandaScraper_product_detail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "createtime = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "FoodpandaScraper = FoodpandaScraper_product_detail()\n",
    "FoodpandaScraper.foodpanda_product_detail(createtime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
